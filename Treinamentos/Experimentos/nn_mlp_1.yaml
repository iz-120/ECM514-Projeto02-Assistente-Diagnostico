model:
  type: "NN MLP"
  param_format: "optuna"

nn:
  hidden_layer_sizes: ["[128,64]", "[64,32]", "[256,128]"]
  activation: ['relu', 'tanh']
  alpha: [1e-05, 1e-04, 1e-03]
  batch_size: [16, 32, 64]
  max_iter: [100, 200]
  early_stopping: [true, false]

train:
  test_size: 0.2
  cv: 3
  random_state: 42

cross_val:
  n_jobs: 2
  scoring: "recall"
  refit: "recall"
  verbose: 1
  n_trials: 5

file: "nn_mlp_1"
