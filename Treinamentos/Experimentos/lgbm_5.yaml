model:
  type: "LightGBM"
  param_format: "Optuna"
  params:
    n_estimators: [300, 500, 800, 1000]
    max_depth: [5, 7, 10, 15, -1]
    learning_rate: [0.005, 0.01, 0.03, 0.05, 0.1]
    num_leaves: [31, 63, 127, 255]
    min_data_in_leaf: [1, 3, 5, 10]
    feature_fraction: [0.7, 0.8, 0.9, 1.0]
    bagging_fraction: [0.7, 0.8, 0.9, 1.0]
    bagging_freq: [1, 3, 5]
    reg_alpha: [0.0, 0.01, 0.1, 0.5]
    reg_lambda: [0.0, 0.01, 0.1, 0.5]
    min_child_weight: [0.001, 0.01, 0.1, 1.0]
    min_split_gain: [0.0, 0.001, 0.01, 0.1]
  fixed_params:
    objective: "binary"
    boosting_type: "gbdt"
    metric: "binary_logloss"
    class_weight: !!null
    verbose: -1

smote:
  sampling_strategy: [0.7, 0.9, 1.0]
  k_neighbors: [3, 5]

train:
  test_size: 0.2
  cv: 3
  random_state: 42

cross_val:
  n_jobs: 2
  scoring: 'recall'
  refit: 'recall'
  verbose: 1
  n_trials: 30

file: "lgbm_5"
