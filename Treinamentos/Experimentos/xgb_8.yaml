model:
  type: "XGBoost"
  param_format: "optuna"
  params:
    n_estimators: [100, 300, 500]
    max_depth: [3, 5, 7, 10]
    learning_rate: [0.01, 0.05, 0.1]
    subsample: [0.6, 0.8, 1.0]
    colsample_bytree: [0.6, 0.8, 1.0]
    gamma: [0, 0.01, 0.1]
    scale_pos_weight: [1, 5, 10, 20]
  fixed_params:
    tree_method: "hist"
    objective: "binary:logistic"

smote:
  sampling_strategy: [0.5, 0.7, 0.9, 1.0]
  k_neighbors: [3, 5, 7]

train:
  test_size: 0.2
  cv: 3
  random_state: 42

cross_val:
  n_trials: 5
  n_jobs: 2
  scoring: "recall"

file: "xgb_8"
